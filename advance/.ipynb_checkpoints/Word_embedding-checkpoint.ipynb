{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input,Embedding,Dense,Flatten\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/semeval_taskA_corrected.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet index  Label                                         Tweet text\n",
       "0            1      1  Sweet United Nations video. Just in time for C...\n",
       "1            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
       "2            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
       "3            4      0                3 episodes left I'm dying over here\n",
       "4            5      1  I can't breathe! was chosen as the most notabl..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncts(data):\n",
    "    new_data = re.sub(r'[^\\w\\s]', '', data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(data):\n",
    "    pattern = r'[0-9]'\n",
    "    new_data = re.sub(pattern, '', data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data['Tweet text'] = data['Tweet text'].str.lower()\n",
    "    data['Tweet text'] = data.apply(lambda x: remove_nums(x['Tweet text']), axis=1)\n",
    "    data['Tweet text'] = data.apply(lambda x: remove_puncts(x['Tweet text']), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sweet united nations video just in time for ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>mrdahl we are rumored to have talked to ervs a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>hey there nice to see you minnesotand winter w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>episodes left im dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>i cant breathe was chosen as the most notable ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet index  Label                                         Tweet text\n",
       "0            1      1  sweet united nations video just in time for ch...\n",
       "1            2      1  mrdahl we are rumored to have talked to ervs a...\n",
       "2            3      1  hey there nice to see you minnesotand winter w...\n",
       "3            4      0                   episodes left im dying over here\n",
       "4            5      1  i cant breathe was chosen as the most notable ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    all_stopwords = sp.Defaults.stop_words\n",
    "    tokens = data.split(\" \")\n",
    "    tokens_filtered= [word for word in tokens if not word in all_stopwords]\n",
    "    return (\" \").join(tokens_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(data):\n",
    "    new_string = ''\n",
    "    doc = sp(data)\n",
    "    for token in doc:\n",
    "        new_string= new_string +\" \"+ str(token.lemma_)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet text'] = data.apply(lambda x: remove_stop_words(x['Tweet text']), axis=1)\n",
    "data['Tweet text'] = data.apply(lambda x: lemmatize(x['Tweet text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_PRON(data):\n",
    "    pattern = r'-PRON-'\n",
    "    new_data = re.sub(pattern, '', data)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet text'] = data.apply(lambda x: remove_PRON(x['Tweet text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sweet united nations video time christmas ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>mrdahl rumor talk ervs agent angel ask ed esc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>hey nice minnesotand winter weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>episode leave  be dying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>can not breathe choose notable quote year ann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet index  Label                                         Tweet text\n",
       "0            1      1   sweet united nations video time christmas ima...\n",
       "1            2      1   mrdahl rumor talk ervs agent angel ask ed esc...\n",
       "2            3      1                hey nice minnesotand winter weather\n",
       "3            4      0                            episode leave  be dying\n",
       "4            5      1   can not breathe choose notable quote year ann..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3834, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Tweet text'], data['Label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004     lloydgallagher  be mate yea good pretty shud ...\n",
       "1028     photoset babaybubblez aquabreeze disgustingho...\n",
       "Name: Tweet text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_word_vectors(X_train):\n",
    "    sentences_as_words=[]\n",
    "    word_to_index={}\n",
    "    count=1\n",
    "    for sent in X_train:\n",
    "        temp = sent.split()\n",
    "        sentences_as_words.append(temp)\n",
    "    for sent in sentences_as_words:\n",
    "        for word in sent:\n",
    "            if word_to_index.get(word,None) is None:\n",
    "                word_to_index[word] = count\n",
    "                count +=1\n",
    "    index_to_word = {v:k for k,v in word_to_index.items()}\n",
    "    sentences=[]\n",
    "    for i in range(len(sentences_as_words)):\n",
    "        temp = [word_to_index[w] for w in sentences_as_words[i]]\n",
    "        sentences.append(temp)\n",
    "\n",
    "\n",
    "    return sentences_as_words,sentences,word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_as_words,sentences,word_ix = prepare_data_for_word_vectors(X_train)\n",
    "sentences_as_words_test, sentences_test, word_ix_test = prepare_data_for_word_vectors(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3067 767\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_as_words), len(sentences_as_words_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_word_vector_model(sentences):\n",
    "    print(\"Training a word2vec model\")\n",
    "    model_w2v = Word2Vec(sentences=sentences, size = 100, workers = 4, window = 5)        \n",
    "    print(\"Training complete\")\n",
    "\n",
    "    print(\"Training a Gensim FastText model\")\n",
    "    model_fasttext = FastText(sentences=sentences, size = 100, workers = 4, window = 5)        \n",
    "\n",
    "    return model_w2v, model_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a word2vec model\n",
      "Training complete\n",
      "Training a Gensim FastText model\n",
      "Training a word2vec model\n",
      "Training complete\n",
      "Training a Gensim FastText model\n"
     ]
    }
   ],
   "source": [
    "trainw2v, trainfast = building_word_vector_model(sentences_as_words)\n",
    "test_w2v,test_fast = building_word_vector_model(sentences_as_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_wv, model_fasttext = building_word_vector_model(sentences, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=773, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(trainw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=773, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(trainfast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=164, size=100, alpha=0.025) FastText(vocab=164, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(test_w2v, test_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors_train(sentence_as_words) :\n",
    "    max_len = 65\n",
    "    vector=[]\n",
    "    for ind_lst in sentences_as_words:\n",
    "        temp =[]\n",
    "        for text in ind_lst:\n",
    "            try:\n",
    "    #             len(modelw2v.wv.get_vector(text)) == 100:\n",
    "                temp.append(trainw2v.wv.get_vector(text))\n",
    "            except:\n",
    "                temp.append(trainw2v.wv.get_vector('be'))\n",
    "\n",
    "        for i in range(65 - len(ind_lst)) :\n",
    "            temp.append(np.zeros(100))\n",
    "        vector.append(temp)\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors_test_fasttext(st) :\n",
    "    max_len = 65\n",
    "    vector=[]\n",
    "    for ind_lst in st:\n",
    "        temp =[]\n",
    "        for text in ind_lst:\n",
    "            try:\n",
    "    #             len(modelw2v.wv.get_vector(text)) == 100:\n",
    "                temp.append(test_fast.wv.get_vector(text))\n",
    "            except:\n",
    "                temp.append(test_fast.wv.get_vector('be'))\n",
    "\n",
    "        for i in range(65 - len(ind_lst)) :\n",
    "            temp.append(np.zeros(100))\n",
    "        vector.append(temp)\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors_train_fasttext(sentence_as_words) :\n",
    "    max_len = 65\n",
    "    vector=[]\n",
    "    for ind_lst in sentences_as_words:\n",
    "        temp =[]\n",
    "        for text in ind_lst:\n",
    "            try:\n",
    "    #             len(modelw2v.wv.get_vector(text)) == 100:\n",
    "                temp.append(trainfast.wv.get_vector(text))\n",
    "            except:\n",
    "                temp.append(trainfast.wv.get_vector('be'))\n",
    "\n",
    "        for i in range(65 - len(ind_lst)) :\n",
    "            temp.append(np.zeros(100))\n",
    "        vector.append(temp)\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors_test(st) :\n",
    "    max_len = 65\n",
    "    vector=[]\n",
    "    for ind_lst in st:\n",
    "        temp =[]\n",
    "        for text in ind_lst:\n",
    "            try:\n",
    "    #             len(modelw2v.wv.get_vector(text)) == 100:\n",
    "                temp.append(test_w2v.wv.get_vector(text))\n",
    "            except:\n",
    "                temp.append(test_w2v.wv.get_vector('be'))\n",
    "\n",
    "        for i in range(65 - len(ind_lst)) :\n",
    "            temp.append(np.zeros(100))\n",
    "        vector.append(temp)\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_vectors_train(sentences_as_words)\n",
    "X_test = create_vectors_test(sentences_as_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = create_vectors_train_fasttext(sentences_as_words)\n",
    "x_test = create_vectors_test_fasttext(sentences_as_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 65, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 65, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 65, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(X_train):\n",
    "    input_seq = Input(shape=(65,100))\n",
    "    x = Dense(128,activation =\"relu\")(input_seq)\n",
    "    x = Flatten()(x)\n",
    "    preds = Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(input_seq,preds)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classification_model(X_train)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 65, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 65, 128)           12928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8321      \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 21,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3067 samples, validate on 767 samples\n",
      "Epoch 1/50\n",
      "3067/3067 [==============================] - 1s 243us/step - loss: 0.6714 - acc: 0.5843 - val_loss: 0.6992 - val_acc: 0.4824\n",
      "Epoch 2/50\n",
      "3067/3067 [==============================] - 1s 224us/step - loss: 0.6702 - acc: 0.5820 - val_loss: 0.6998 - val_acc: 0.4824\n",
      "Epoch 3/50\n",
      "3067/3067 [==============================] - 1s 218us/step - loss: 0.6705 - acc: 0.5784 - val_loss: 0.6967 - val_acc: 0.4954\n",
      "Epoch 4/50\n",
      "3067/3067 [==============================] - 1s 224us/step - loss: 0.6708 - acc: 0.5823 - val_loss: 0.7024 - val_acc: 0.4811\n",
      "Epoch 5/50\n",
      "3067/3067 [==============================] - 1s 222us/step - loss: 0.6698 - acc: 0.5794 - val_loss: 0.7056 - val_acc: 0.4811\n",
      "Epoch 6/50\n",
      "3067/3067 [==============================] - 1s 227us/step - loss: 0.6704 - acc: 0.5794 - val_loss: 0.7047 - val_acc: 0.4811\n",
      "Epoch 7/50\n",
      "3067/3067 [==============================] - 1s 222us/step - loss: 0.6675 - acc: 0.5918 - val_loss: 0.7005 - val_acc: 0.4824\n",
      "Epoch 8/50\n",
      "3067/3067 [==============================] - 1s 223us/step - loss: 0.6677 - acc: 0.5840 - val_loss: 0.7085 - val_acc: 0.4811\n",
      "Epoch 9/50\n",
      "3067/3067 [==============================] - 1s 222us/step - loss: 0.6677 - acc: 0.5869 - val_loss: 0.7062 - val_acc: 0.4811\n",
      "Epoch 10/50\n",
      "3067/3067 [==============================] - 1s 224us/step - loss: 0.6693 - acc: 0.5853 - val_loss: 0.7074 - val_acc: 0.4811\n",
      "Epoch 11/50\n",
      "3067/3067 [==============================] - 1s 237us/step - loss: 0.6687 - acc: 0.5879 - val_loss: 0.7113 - val_acc: 0.4811\n",
      "Epoch 12/50\n",
      "3067/3067 [==============================] - 1s 265us/step - loss: 0.6670 - acc: 0.5921 - val_loss: 0.7156 - val_acc: 0.4811\n",
      "Epoch 13/50\n",
      "3067/3067 [==============================] - 1s 215us/step - loss: 0.6660 - acc: 0.5771 - val_loss: 0.7136 - val_acc: 0.4811\n",
      "Epoch 14/50\n",
      "3067/3067 [==============================] - 1s 239us/step - loss: 0.6678 - acc: 0.5797 - val_loss: 0.7146 - val_acc: 0.4811\n",
      "Epoch 15/50\n",
      "3067/3067 [==============================] - 1s 227us/step - loss: 0.6662 - acc: 0.5977 - val_loss: 0.7070 - val_acc: 0.4824\n",
      "Epoch 16/50\n",
      "3067/3067 [==============================] - 1s 241us/step - loss: 0.6663 - acc: 0.5853 - val_loss: 0.7113 - val_acc: 0.4811\n",
      "Epoch 17/50\n",
      "3067/3067 [==============================] - 1s 308us/step - loss: 0.6673 - acc: 0.5830 - val_loss: 0.7127 - val_acc: 0.4811\n",
      "Epoch 18/50\n",
      "3067/3067 [==============================] - 1s 299us/step - loss: 0.6663 - acc: 0.5882 - val_loss: 0.7125 - val_acc: 0.4811\n",
      "Epoch 19/50\n",
      "3067/3067 [==============================] - 1s 281us/step - loss: 0.6649 - acc: 0.5859 - val_loss: 0.7125 - val_acc: 0.4811\n",
      "Epoch 20/50\n",
      "3067/3067 [==============================] - 1s 241us/step - loss: 0.6669 - acc: 0.5853 - val_loss: 0.7133 - val_acc: 0.4811\n",
      "Epoch 21/50\n",
      "3067/3067 [==============================] - 1s 290us/step - loss: 0.6653 - acc: 0.5950 - val_loss: 0.7176 - val_acc: 0.4811\n",
      "Epoch 22/50\n",
      "3067/3067 [==============================] - 1s 225us/step - loss: 0.6661 - acc: 0.5902 - val_loss: 0.7184 - val_acc: 0.4811\n",
      "Epoch 23/50\n",
      "3067/3067 [==============================] - 1s 254us/step - loss: 0.6630 - acc: 0.5869 - val_loss: 0.7270 - val_acc: 0.4811\n",
      "Epoch 24/50\n",
      "3067/3067 [==============================] - 1s 231us/step - loss: 0.6648 - acc: 0.5934 - val_loss: 0.7211 - val_acc: 0.4811\n",
      "Epoch 25/50\n",
      "3067/3067 [==============================] - 1s 190us/step - loss: 0.6636 - acc: 0.6006 - val_loss: 0.7166 - val_acc: 0.4811\n",
      "Epoch 26/50\n",
      "3067/3067 [==============================] - 1s 275us/step - loss: 0.6628 - acc: 0.5937 - val_loss: 0.7211 - val_acc: 0.4811\n",
      "Epoch 27/50\n",
      "3067/3067 [==============================] - 1s 278us/step - loss: 0.6635 - acc: 0.5911 - val_loss: 0.7146 - val_acc: 0.4824\n",
      "Epoch 28/50\n",
      "3067/3067 [==============================] - 1s 260us/step - loss: 0.6637 - acc: 0.5947 - val_loss: 0.7243 - val_acc: 0.4811\n",
      "Epoch 29/50\n",
      "3067/3067 [==============================] - 1s 262us/step - loss: 0.6644 - acc: 0.5944 - val_loss: 0.7221 - val_acc: 0.4811\n",
      "Epoch 30/50\n",
      "3067/3067 [==============================] - 1s 242us/step - loss: 0.6616 - acc: 0.6032 - val_loss: 0.7351 - val_acc: 0.4811\n",
      "Epoch 31/50\n",
      "3067/3067 [==============================] - 1s 235us/step - loss: 0.6636 - acc: 0.5885 - val_loss: 0.7215 - val_acc: 0.4811\n",
      "Epoch 32/50\n",
      "3067/3067 [==============================] - 1s 254us/step - loss: 0.6626 - acc: 0.5895 - val_loss: 0.7253 - val_acc: 0.4811\n",
      "Epoch 33/50\n",
      "3067/3067 [==============================] - 1s 267us/step - loss: 0.6604 - acc: 0.6003 - val_loss: 0.7248 - val_acc: 0.4811\n",
      "Epoch 34/50\n",
      "3067/3067 [==============================] - 1s 252us/step - loss: 0.6610 - acc: 0.5928 - val_loss: 0.7339 - val_acc: 0.4811\n",
      "Epoch 35/50\n",
      "3067/3067 [==============================] - 1s 237us/step - loss: 0.6602 - acc: 0.5977 - val_loss: 0.7286 - val_acc: 0.4811\n",
      "Epoch 36/50\n",
      "3067/3067 [==============================] - 1s 259us/step - loss: 0.6602 - acc: 0.6012 - val_loss: 0.7311 - val_acc: 0.4811\n",
      "Epoch 37/50\n",
      "3067/3067 [==============================] - 1s 302us/step - loss: 0.6604 - acc: 0.5954 - val_loss: 0.7307 - val_acc: 0.4811\n",
      "Epoch 38/50\n",
      "3067/3067 [==============================] - 1s 291us/step - loss: 0.6595 - acc: 0.5924 - val_loss: 0.7305 - val_acc: 0.4811\n",
      "Epoch 39/50\n",
      "3067/3067 [==============================] - 1s 295us/step - loss: 0.6591 - acc: 0.5996 - val_loss: 0.7316 - val_acc: 0.4811\n",
      "Epoch 40/50\n",
      "3067/3067 [==============================] - 1s 278us/step - loss: 0.6590 - acc: 0.5957 - val_loss: 0.7353 - val_acc: 0.4811\n",
      "Epoch 41/50\n",
      "3067/3067 [==============================] - 1s 236us/step - loss: 0.6581 - acc: 0.5990 - val_loss: 0.7303 - val_acc: 0.4824\n",
      "Epoch 42/50\n",
      "3067/3067 [==============================] - 1s 230us/step - loss: 0.6585 - acc: 0.6055 - val_loss: 0.7385 - val_acc: 0.4811\n",
      "Epoch 43/50\n",
      "3067/3067 [==============================] - 1s 267us/step - loss: 0.6586 - acc: 0.6029 - val_loss: 0.7395 - val_acc: 0.4811\n",
      "Epoch 44/50\n",
      "3067/3067 [==============================] - 1s 270us/step - loss: 0.6573 - acc: 0.6009 - val_loss: 0.7371 - val_acc: 0.4811\n",
      "Epoch 45/50\n",
      "3067/3067 [==============================] - 1s 256us/step - loss: 0.6573 - acc: 0.6045 - val_loss: 0.7403 - val_acc: 0.4811\n",
      "Epoch 46/50\n",
      "3067/3067 [==============================] - 1s 255us/step - loss: 0.6574 - acc: 0.6038 - val_loss: 0.7315 - val_acc: 0.4824\n",
      "Epoch 47/50\n",
      "3067/3067 [==============================] - 1s 296us/step - loss: 0.6582 - acc: 0.6074 - val_loss: 0.7417 - val_acc: 0.4811\n",
      "Epoch 48/50\n",
      "3067/3067 [==============================] - 1s 265us/step - loss: 0.6565 - acc: 0.6042 - val_loss: 0.7556 - val_acc: 0.4811\n",
      "Epoch 49/50\n",
      "3067/3067 [==============================] - 1s 263us/step - loss: 0.6564 - acc: 0.6065 - val_loss: 0.7310 - val_acc: 0.4811\n",
      "Epoch 50/50\n",
      "3067/3067 [==============================] - 1s 257us/step - loss: 0.6577 - acc: 0.6035 - val_loss: 0.7324 - val_acc: 0.4811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1899daf60>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test)) # word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fast = model = classification_model(x_train)\n",
    "model_fast.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 65, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 65, 128)           12928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 8321      \n",
      "=================================================================\n",
      "Total params: 21,249\n",
      "Trainable params: 21,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fast.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3067 samples, validate on 767 samples\n",
      "Epoch 1/50\n",
      "3067/3067 [==============================] - 1s 367us/step - loss: 0.6924 - acc: 0.5139 - val_loss: 0.6937 - val_acc: 0.4811\n",
      "Epoch 2/50\n",
      "3067/3067 [==============================] - 1s 225us/step - loss: 0.6882 - acc: 0.5478 - val_loss: 0.7052 - val_acc: 0.4811\n",
      "Epoch 3/50\n",
      "3067/3067 [==============================] - 1s 225us/step - loss: 0.6857 - acc: 0.5425 - val_loss: 0.7115 - val_acc: 0.4811\n",
      "Epoch 4/50\n",
      "3067/3067 [==============================] - 1s 227us/step - loss: 0.6847 - acc: 0.5517 - val_loss: 0.7110 - val_acc: 0.4811\n",
      "Epoch 5/50\n",
      "3067/3067 [==============================] - 1s 267us/step - loss: 0.6844 - acc: 0.5562 - val_loss: 0.7237 - val_acc: 0.4811\n",
      "Epoch 6/50\n",
      "3067/3067 [==============================] - 1s 246us/step - loss: 0.6845 - acc: 0.5556 - val_loss: 0.7189 - val_acc: 0.4811\n",
      "Epoch 7/50\n",
      "3067/3067 [==============================] - 1s 232us/step - loss: 0.6854 - acc: 0.5530 - val_loss: 0.7118 - val_acc: 0.4811\n",
      "Epoch 8/50\n",
      "3067/3067 [==============================] - 1s 241us/step - loss: 0.6832 - acc: 0.5618 - val_loss: 0.7112 - val_acc: 0.4811\n",
      "Epoch 9/50\n",
      "3067/3067 [==============================] - 1s 233us/step - loss: 0.6832 - acc: 0.5631 - val_loss: 0.7157 - val_acc: 0.4811\n",
      "Epoch 10/50\n",
      "3067/3067 [==============================] - 1s 276us/step - loss: 0.6835 - acc: 0.5494 - val_loss: 0.7194 - val_acc: 0.4811\n",
      "Epoch 11/50\n",
      "3067/3067 [==============================] - 1s 257us/step - loss: 0.6827 - acc: 0.5624 - val_loss: 0.7211 - val_acc: 0.4811\n",
      "Epoch 12/50\n",
      "3067/3067 [==============================] - 1s 233us/step - loss: 0.6830 - acc: 0.5579 - val_loss: 0.7198 - val_acc: 0.4811\n",
      "Epoch 13/50\n",
      "3067/3067 [==============================] - 1s 285us/step - loss: 0.6813 - acc: 0.5595 - val_loss: 0.7205 - val_acc: 0.4811\n",
      "Epoch 14/50\n",
      "3067/3067 [==============================] - 1s 263us/step - loss: 0.6812 - acc: 0.5579 - val_loss: 0.7052 - val_acc: 0.4811\n",
      "Epoch 15/50\n",
      "3067/3067 [==============================] - 1s 246us/step - loss: 0.6818 - acc: 0.5618 - val_loss: 0.7144 - val_acc: 0.4811\n",
      "Epoch 16/50\n",
      "3067/3067 [==============================] - 1s 245us/step - loss: 0.6798 - acc: 0.5637 - val_loss: 0.7175 - val_acc: 0.4811\n",
      "Epoch 17/50\n",
      "3067/3067 [==============================] - 1s 263us/step - loss: 0.6814 - acc: 0.5699 - val_loss: 0.7139 - val_acc: 0.4811\n",
      "Epoch 18/50\n",
      "3067/3067 [==============================] - 1s 244us/step - loss: 0.6815 - acc: 0.5602 - val_loss: 0.7068 - val_acc: 0.4811\n",
      "Epoch 19/50\n",
      "3067/3067 [==============================] - 1s 291us/step - loss: 0.6804 - acc: 0.5634 - val_loss: 0.7118 - val_acc: 0.4811\n",
      "Epoch 20/50\n",
      "3067/3067 [==============================] - 1s 264us/step - loss: 0.6791 - acc: 0.5699 - val_loss: 0.7139 - val_acc: 0.4811\n",
      "Epoch 21/50\n",
      "3067/3067 [==============================] - 1s 285us/step - loss: 0.6802 - acc: 0.5631 - val_loss: 0.7324 - val_acc: 0.4811\n",
      "Epoch 22/50\n",
      "3067/3067 [==============================] - 1s 276us/step - loss: 0.6797 - acc: 0.5611 - val_loss: 0.7286 - val_acc: 0.4811\n",
      "Epoch 23/50\n",
      "3067/3067 [==============================] - 1s 244us/step - loss: 0.6792 - acc: 0.5664 - val_loss: 0.7180 - val_acc: 0.4811\n",
      "Epoch 24/50\n",
      "3067/3067 [==============================] - 1s 237us/step - loss: 0.6784 - acc: 0.5670 - val_loss: 0.7240 - val_acc: 0.4811\n",
      "Epoch 25/50\n",
      "3067/3067 [==============================] - 1s 249us/step - loss: 0.6785 - acc: 0.5660 - val_loss: 0.7267 - val_acc: 0.4811\n",
      "Epoch 26/50\n",
      "3067/3067 [==============================] - 1s 274us/step - loss: 0.6773 - acc: 0.5729 - val_loss: 0.7275 - val_acc: 0.4811\n",
      "Epoch 27/50\n",
      "3067/3067 [==============================] - 1s 271us/step - loss: 0.6774 - acc: 0.5647 - val_loss: 0.7420 - val_acc: 0.4811\n",
      "Epoch 28/50\n",
      "3067/3067 [==============================] - 1s 315us/step - loss: 0.6763 - acc: 0.5680 - val_loss: 0.7477 - val_acc: 0.4811\n",
      "Epoch 29/50\n",
      "3067/3067 [==============================] - 1s 271us/step - loss: 0.6773 - acc: 0.5670 - val_loss: 0.7256 - val_acc: 0.4811\n",
      "Epoch 30/50\n",
      "3067/3067 [==============================] - 1s 311us/step - loss: 0.6792 - acc: 0.5657 - val_loss: 0.7312 - val_acc: 0.4811\n",
      "Epoch 31/50\n",
      "3067/3067 [==============================] - 1s 270us/step - loss: 0.6787 - acc: 0.5667 - val_loss: 0.7419 - val_acc: 0.4811\n",
      "Epoch 32/50\n",
      "3067/3067 [==============================] - 1s 299us/step - loss: 0.6784 - acc: 0.5575 - val_loss: 0.7187 - val_acc: 0.4811\n",
      "Epoch 33/50\n",
      "3067/3067 [==============================] - 1s 325us/step - loss: 0.6767 - acc: 0.5602 - val_loss: 0.7328 - val_acc: 0.4811\n",
      "Epoch 34/50\n",
      "3067/3067 [==============================] - 1s 328us/step - loss: 0.6759 - acc: 0.5742 - val_loss: 0.7391 - val_acc: 0.4811\n",
      "Epoch 35/50\n",
      "3067/3067 [==============================] - 1s 260us/step - loss: 0.6755 - acc: 0.5804 - val_loss: 0.7430 - val_acc: 0.4811\n",
      "Epoch 36/50\n",
      "3067/3067 [==============================] - 1s 257us/step - loss: 0.6749 - acc: 0.5673 - val_loss: 0.7536 - val_acc: 0.4811\n",
      "Epoch 37/50\n",
      "3067/3067 [==============================] - 1s 239us/step - loss: 0.6765 - acc: 0.5706 - val_loss: 0.7438 - val_acc: 0.4811\n",
      "Epoch 38/50\n",
      "3067/3067 [==============================] - 1s 320us/step - loss: 0.6766 - acc: 0.5608 - val_loss: 0.7461 - val_acc: 0.4811\n",
      "Epoch 39/50\n",
      "3067/3067 [==============================] - 1s 277us/step - loss: 0.6753 - acc: 0.5748 - val_loss: 0.7554 - val_acc: 0.4811\n",
      "Epoch 40/50\n",
      "3067/3067 [==============================] - 1s 262us/step - loss: 0.6744 - acc: 0.5765 - val_loss: 0.7465 - val_acc: 0.4811\n",
      "Epoch 41/50\n",
      "3067/3067 [==============================] - 1s 257us/step - loss: 0.6726 - acc: 0.5804 - val_loss: 0.7412 - val_acc: 0.4811\n",
      "Epoch 42/50\n",
      "3067/3067 [==============================] - 1s 250us/step - loss: 0.6741 - acc: 0.5686 - val_loss: 0.7390 - val_acc: 0.4811\n",
      "Epoch 43/50\n",
      "3067/3067 [==============================] - 1s 246us/step - loss: 0.6736 - acc: 0.5654 - val_loss: 0.7323 - val_acc: 0.4811\n",
      "Epoch 44/50\n",
      "3067/3067 [==============================] - 1s 238us/step - loss: 0.6727 - acc: 0.5765 - val_loss: 0.7270 - val_acc: 0.4811\n",
      "Epoch 45/50\n",
      "3067/3067 [==============================] - 1s 264us/step - loss: 0.6740 - acc: 0.5739 - val_loss: 0.7628 - val_acc: 0.4811\n",
      "Epoch 46/50\n",
      "3067/3067 [==============================] - 1s 286us/step - loss: 0.6735 - acc: 0.5712 - val_loss: 0.7374 - val_acc: 0.4811\n",
      "Epoch 47/50\n",
      "3067/3067 [==============================] - 1s 271us/step - loss: 0.6736 - acc: 0.5690 - val_loss: 0.7531 - val_acc: 0.4811\n",
      "Epoch 48/50\n",
      "3067/3067 [==============================] - 1s 262us/step - loss: 0.6729 - acc: 0.5608 - val_loss: 0.7583 - val_acc: 0.4811\n",
      "Epoch 49/50\n",
      "3067/3067 [==============================] - 1s 273us/step - loss: 0.6719 - acc: 0.5810 - val_loss: 0.8074 - val_acc: 0.4811\n",
      "Epoch 50/50\n",
      "3067/3067 [==============================] - 1s 254us/step - loss: 0.6726 - acc: 0.5693 - val_loss: 0.7593 - val_acc: 0.4811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d3a09e8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fast.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test)) #fasttetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
